{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Python Spark regression example\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format('com.databricks.spark.csv').\\\n",
    "                       options(header='true', \\\n",
    "                       inferschema='true').\\\n",
    "            load(\"../data/Advertising.csv\",header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+---------+-----+\n",
      "|   TV|Radio|Newspaper|Sales|\n",
      "+-----+-----+---------+-----+\n",
      "|230.1| 37.8|     69.2| 22.1|\n",
      "| 44.5| 39.3|     45.1| 10.4|\n",
      "| 17.2| 45.9|     69.3|  9.3|\n",
      "|151.5| 41.3|     58.5| 18.5|\n",
      "|180.8| 10.8|     58.4| 12.9|\n",
      "+-----+-----+---------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- TV: double (nullable = true)\n",
      " |-- Radio: double (nullable = true)\n",
      " |-- Newspaper: double (nullable = true)\n",
      " |-- Sales: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5,True)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+------------------+------------------+\n",
      "|summary|               TV|             Radio|         Newspaper|             Sales|\n",
      "+-------+-----------------+------------------+------------------+------------------+\n",
      "|  count|              200|               200|               200|               200|\n",
      "|   mean|         147.0425|23.264000000000024|30.553999999999995|14.022500000000003|\n",
      "| stddev|85.85423631490805|14.846809176168728| 21.77862083852283| 5.217456565710477|\n",
      "|    min|              0.7|               0.0|               0.3|               1.6|\n",
      "|    max|            296.4|              49.6|             114.0|              27.0|\n",
      "+-------+-----------------+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "from pyspark.ml.linalg import Vectors\n",
    "\n",
    "# I provide two ways to build the features and labels\n",
    "\n",
    "# method 1 (good for small feature):\n",
    "#def transData(row):\n",
    "#    return Row(label=row[\"Sales\"],\n",
    "#               features=Vectors.dense([row[\"TV\"],\n",
    "#                                       row[\"Radio\"],\n",
    "#                                       row[\"Newspaper\"]]))\n",
    "\n",
    "# Method 2 (good for large features):\n",
    "def transData(data):\n",
    "    return data.rdd.map(lambda r: [Vectors.dense(r[:-1]),r[-1]]).toDF(['features','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+\n",
      "|         features|label|\n",
      "+-----------------+-----+\n",
      "|[230.1,37.8,69.2]| 22.1|\n",
      "| [44.5,39.3,45.1]| 10.4|\n",
      "| [17.2,45.9,69.3]|  9.3|\n",
      "|[151.5,41.3,58.5]| 18.5|\n",
      "|[180.8,10.8,58.4]| 12.9|\n",
      "+-----------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transformed= transData(df)\n",
    "transformed.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------------+\n",
      "|label|         features|\n",
      "+-----+-----------------+\n",
      "| 22.1|[230.1,37.8,69.2]|\n",
      "| 10.4| [44.5,39.3,45.1]|\n",
      "|  9.3| [17.2,45.9,69.3]|\n",
      "| 18.5|[151.5,41.3,58.5]|\n",
      "| 12.9|[180.8,10.8,58.4]|\n",
      "|  7.2|  [8.7,48.9,75.0]|\n",
      "| 11.8| [57.5,32.8,23.5]|\n",
      "| 13.2|[120.2,19.6,11.6]|\n",
      "|  4.8|    [8.6,2.1,1.0]|\n",
      "| 10.6| [199.8,2.6,21.2]|\n",
      "|  8.6|  [66.1,5.8,24.2]|\n",
      "| 17.4| [214.7,24.0,4.0]|\n",
      "|  9.2| [23.8,35.1,65.9]|\n",
      "|  9.7|   [97.5,7.6,7.2]|\n",
      "| 19.0|[204.1,32.9,46.0]|\n",
      "| 22.4|[195.4,47.7,52.9]|\n",
      "| 12.5|[67.8,36.6,114.0]|\n",
      "| 24.4|[281.4,39.6,55.8]|\n",
      "| 11.3| [69.2,20.5,18.3]|\n",
      "| 14.6|[147.3,23.9,19.1]|\n",
      "+-----+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#convert data to dense vector\n",
    "# convert the data to dense vector\n",
    "def transData(data):\n",
    "    return data.rdd.map(lambda r: [r[-1], Vectors.dense(r[:-1])]).\\\n",
    "           toDF(['label','features'])\n",
    "\n",
    "from pyspark.sql import Row\n",
    "from pyspark.ml.linalg import Vectors\n",
    "\n",
    "data= transData(df)\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deal with categorical variables\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.feature import VectorIndexer\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Automatically identify categorical features, and index them.\n",
    "# We specify maxCategories so features with > 4\n",
    "# distinct values are treated as continuous.\n",
    "\n",
    "featureIndexer = VectorIndexer(inputCol=\"features\", \\\n",
    "                               outputCol=\"indexedFeatures\",\\\n",
    "                               maxCategories=4).fit(transformed)\n",
    "\n",
    "data = featureIndexer.transform(transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets (40% held out for testing)\n",
    "(trainingData, testData) = transformed.randomSplit([0.6, 0.4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----+\n",
      "|       features|label|\n",
      "+---------------+-----+\n",
      "| [0.7,39.6,8.7]|  1.6|\n",
      "| [4.1,11.6,5.7]|  3.2|\n",
      "| [5.4,29.9,9.4]|  5.3|\n",
      "|[7.8,38.9,50.6]|  6.6|\n",
      "| [8.4,27.2,2.1]|  5.7|\n",
      "+---------------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "+----------------+-----+\n",
      "|        features|label|\n",
      "+----------------+-----+\n",
      "| [7.3,28.1,41.4]|  5.5|\n",
      "| [8.7,48.9,75.0]|  7.2|\n",
      "|[11.7,36.9,45.2]|  7.3|\n",
      "| [13.1,0.4,25.6]|  5.3|\n",
      "|[17.2,45.9,69.3]|  9.3|\n",
      "+----------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainingData.show(5)\n",
    "testData.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import LinearRegression class\n",
    "from pyspark.ml.regression import GeneralizedLinearRegression\n",
    "\n",
    "# Define LinearRegression algorithm\n",
    "glr = GeneralizedLinearRegression(family=\"gaussian\", link=\"identity\",\\\n",
    "                                  maxIter=10, regParam=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain indexer and tree in a Pipeline\n",
    "pipeline = Pipeline(stages=[featureIndexer, glr])\n",
    "\n",
    "model = pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelsummary(model):\n",
    "    import numpy as np\n",
    "    print (\"Note: the last rows are the information for Intercept\")\n",
    "    print (\"##\",\"-------------------------------------------------\")\n",
    "    print (\"##\",\"  Estimate   |   Std.Error | t Values  |  P-value\")\n",
    "    coef = np.append(list(model.coefficients),model.intercept)\n",
    "    Summary=model.summary\n",
    "\n",
    "    for i in range(len(Summary.pValues)):\n",
    "        print (\"##\",'{:10.6f}'.format(coef[i]),\\\n",
    "        '{:10.6f}'.format(Summary.coefficientStandardErrors[i]),\\\n",
    "        '{:8.3f}'.format(Summary.tValues[i]),\\\n",
    "        '{:10.6f}'.format(Summary.pValues[i]))\n",
    "\n",
    "    print (\"##\",'---')\n",
    "#     print (\"##\",\"Mean squared error: % .6f\" \\\n",
    "#            % Summary.meanSquaredError, \", RMSE: % .6f\" \\\n",
    "#            % Summary.rootMeanSquaredError )\n",
    "#     print (\"##\",\"Multiple R-squared: %f\" % Summary.r2, \", \\\n",
    "#             Total iterations: %i\"% Summary.totalIterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: the last rows are the information for Intercept\n",
      "## -------------------------------------------------\n",
      "##   Estimate   |   Std.Error | t Values  |  P-value\n",
      "##   0.042681   0.001892   22.564   0.000000\n",
      "##   0.189469   0.011644   16.272   0.000000\n",
      "##   0.000244   0.007758    0.032   0.974925\n",
      "##   3.245604   0.421313    7.704   0.000000\n",
      "## ---\n"
     ]
    }
   ],
   "source": [
    "modelsummary(model.stages[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions.\n",
    "predictions = model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----+------------------+\n",
      "|        features|label|        prediction|\n",
      "+----------------+-----+------------------+\n",
      "| [7.3,28.1,41.4]|  5.5|  8.89136992228887|\n",
      "| [8.7,48.9,75.0]|  7.2|12.900288264771042|\n",
      "|[11.7,36.9,45.2]|  7.3|10.747422021751568|\n",
      "| [13.1,0.4,25.6]|  5.3|3.8867707344668174|\n",
      "|[17.2,45.9,69.3]|  9.3|12.693278371797728|\n",
      "+----------------+-----+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select example rows to display.\n",
    "predictions.select(\"features\",\"label\",\"prediction\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 1.59258\n"
     ]
    }
   ],
   "source": [
    "#Evaluation\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = RegressionEvaluator(labelCol=\"label\",\n",
    "                                predictionCol=\"prediction\",\n",
    "                                metricName=\"rmse\")\n",
    "\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score: 0.9030687189774794\n"
     ]
    }
   ],
   "source": [
    "y_true = predictions.select(\"label\").toPandas()\n",
    "y_pred = predictions.select(\"prediction\").toPandas()\n",
    "\n",
    "import sklearn.metrics\n",
    "r2_score = sklearn.metrics.r2_score(y_true, y_pred)\n",
    "print('r2_score: {0}'.format(r2_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree Regression\n",
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "\n",
    "# Train a DecisionTree model.\n",
    "dt = DecisionTreeRegressor(featuresCol=\"indexedFeatures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain indexer and tree in a Pipeline\n",
    "pipeline = Pipeline(stages=[featureIndexer, dt])\n",
    "\n",
    "model = pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions.\n",
    "predictions = model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----+----------+\n",
      "|        features|label|prediction|\n",
      "+----------------+-----+----------+\n",
      "| [7.3,28.1,41.4]|  5.5|     7.425|\n",
      "| [8.7,48.9,75.0]|  7.2|       8.7|\n",
      "|[11.7,36.9,45.2]|  7.3|     7.425|\n",
      "| [13.1,0.4,25.6]|  5.3|       6.2|\n",
      "|[17.2,45.9,69.3]|  9.3|       8.7|\n",
      "+----------------+-----+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select example rows to display.\n",
    "predictions.select(\"features\",\"label\",\"prediction\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 1.39311\n"
     ]
    }
   ],
   "source": [
    "#Evaluation\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = RegressionEvaluator(labelCol=\"label\",\n",
    "                                predictionCol=\"prediction\",\n",
    "                                metricName=\"rmse\")\n",
    "\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score: 0.9258284860063273\n"
     ]
    }
   ],
   "source": [
    "y_true = predictions.select(\"label\").toPandas()\n",
    "y_pred = predictions.select(\"prediction\").toPandas()\n",
    "\n",
    "import sklearn.metrics\n",
    "r2_score = sklearn.metrics.r2_score(y_true, y_pred)\n",
    "print('r2_score: {0}'.format(r2_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(3, {0: 0.6052, 1: 0.3822, 2: 0.0126})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check importance of the features\n",
    "model.stages[1].featureImportances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest Regression\n",
    "# Import LinearRegression class\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "\n",
    "# Define LinearRegression algorithm\n",
    "rf = RandomForestRegressor() # featuresCol=\"indexedFeatures\",numTrees=2, maxDepth=2, seed=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain indexer and tree in a Pipeline\n",
    "pipeline = Pipeline(stages=[featureIndexer, rf])\n",
    "model = pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----+------------------+\n",
      "|        features|label|        prediction|\n",
      "+----------------+-----+------------------+\n",
      "| [7.3,28.1,41.4]|  5.5|10.590133669392182|\n",
      "| [8.7,48.9,75.0]|  7.2|13.928263888888889|\n",
      "|[11.7,36.9,45.2]|  7.3|10.834172130930645|\n",
      "| [13.1,0.4,25.6]|  5.3| 8.416003599748988|\n",
      "|[17.2,45.9,69.3]|  9.3|12.391805555555555|\n",
      "+----------------+-----+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = model.transform(testData)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"features\",\"label\", \"prediction\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 2.55544\n"
     ]
    }
   ],
   "source": [
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score: 0.926\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics\n",
    "r2_score = sklearn.metrics.r2_score(y_true, y_pred)\n",
    "print('r2_score: {:4.3f}'.format(r2_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(3, {0: 0.4518, 1: 0.3419, 2: 0.2062})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.stages[-1].featureImportances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DecisionTreeRegressionModel (uid=dtr_66570b310ce0) of depth 5 with 47 nodes,\n",
       " DecisionTreeRegressionModel (uid=dtr_bf4e9b70d812) of depth 5 with 51 nodes,\n",
       " DecisionTreeRegressionModel (uid=dtr_8a8684692d28) of depth 5 with 51 nodes,\n",
       " DecisionTreeRegressionModel (uid=dtr_91363a1efb74) of depth 5 with 35 nodes,\n",
       " DecisionTreeRegressionModel (uid=dtr_935bff219b09) of depth 5 with 37 nodes,\n",
       " DecisionTreeRegressionModel (uid=dtr_a8661ecbfcbf) of depth 5 with 47 nodes,\n",
       " DecisionTreeRegressionModel (uid=dtr_4446cd7ab95b) of depth 5 with 41 nodes,\n",
       " DecisionTreeRegressionModel (uid=dtr_db147add49e2) of depth 5 with 47 nodes,\n",
       " DecisionTreeRegressionModel (uid=dtr_2177275ff459) of depth 5 with 41 nodes,\n",
       " DecisionTreeRegressionModel (uid=dtr_0cfb24ddc428) of depth 5 with 43 nodes,\n",
       " DecisionTreeRegressionModel (uid=dtr_ebe0ed866ff0) of depth 5 with 41 nodes,\n",
       " DecisionTreeRegressionModel (uid=dtr_a1b8f757049d) of depth 5 with 43 nodes,\n",
       " DecisionTreeRegressionModel (uid=dtr_ceb9fb380cf8) of depth 5 with 41 nodes,\n",
       " DecisionTreeRegressionModel (uid=dtr_40bb20ec4092) of depth 5 with 35 nodes,\n",
       " DecisionTreeRegressionModel (uid=dtr_50c3b1f29703) of depth 5 with 49 nodes,\n",
       " DecisionTreeRegressionModel (uid=dtr_dfd594921d89) of depth 5 with 39 nodes,\n",
       " DecisionTreeRegressionModel (uid=dtr_49404829ffa4) of depth 5 with 41 nodes,\n",
       " DecisionTreeRegressionModel (uid=dtr_1f12807a846c) of depth 5 with 55 nodes,\n",
       " DecisionTreeRegressionModel (uid=dtr_4f230ea8458c) of depth 5 with 53 nodes,\n",
       " DecisionTreeRegressionModel (uid=dtr_7b39ec6005cf) of depth 5 with 45 nodes]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.stages[-1].trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gradient Boosted Decision Trees\n",
    "# Import LinearRegression class\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "\n",
    "# Define LinearRegression algorithm\n",
    "rf = GBTRegressor() #numTrees=2, maxDepth=2, seed=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain indexer and tree in a Pipeline\n",
    "pipeline = Pipeline(stages=[featureIndexer, rf])\n",
    "model = pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----+------------------+\n",
      "|        features|label|        prediction|\n",
      "+----------------+-----+------------------+\n",
      "| [7.3,28.1,41.4]|  5.5| 6.946822197156063|\n",
      "| [8.7,48.9,75.0]|  7.2|7.4928311748441665|\n",
      "|[11.7,36.9,45.2]|  7.3| 7.581659086163565|\n",
      "| [13.1,0.4,25.6]|  5.3| 5.960418134307112|\n",
      "|[17.2,45.9,69.3]|  9.3| 7.974055476837845|\n",
      "+----------------+-----+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = model.transform(testData)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"features\",\"label\", \"prediction\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 1.2784\n"
     ]
    }
   ],
   "source": [
    "#Evaluation\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score: 0.926\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics\n",
    "r2_score = sklearn.metrics.r2_score(y_true, y_pred)\n",
    "print('r2_score: {:4.3f}'.format(r2_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(3, {0: 0.3482, 1: 0.3294, 2: 0.3224})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.stages[-1].featureImportances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
